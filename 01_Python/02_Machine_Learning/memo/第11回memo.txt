分類モデルの評価など


医療データ=load_breast_cancer() 
サーキットラーンの、データセットの読み込み（アメリカで行われたがん検査の結果）
機械学習の練習をしたい時に便利。

LogisticRegression()
ロジスティック回帰（分類）
サンプル毎に、それぞれのクラスに属する確率を予測
それぞれのクラスに属する確率を予測。確率が閾値を超えるかどうかで分類する。

・正解率
accuracy_score(目的変数y,予測されたy)
（全ての確率が分母に。正解した確率のみが分子にくる。）
(TP + TN)  (TP + TN + FP + FN)

・適合率
precision_score(目的変数y,予測されたy)
（ポジティブと予測された中で、どれだけが本当にポジティブであったか。）
陽性反応的中度
これが低いと、陰性なのに不安にさせる人を増やすことになる。
TP / (TP + FP)

・再現率
recall_score(目的変数y,予測されたy)
実際にポジティブであった中で、どれだけをポジティブと予想できたか
真陽性率
これが低いと、病気の見落としにつながる。
TP / (TP + FN)


confusion_matrix(目的変数y,予測されたy)
TP、TN、FP、FNを行列で出してくれる



F値（適合率, 再現率の両方を考慮した値
適合率と再現率の調和平均 ポジティブとネガティブの割合が極端に異なっていても評価しやすい


ROC曲線
評価のためのグラフ
Xに偽陽性率、Yに真陽性率
面積は「AUC」範囲は0~1で、1に近づくほど、予測がうまくいっているということ。



==================================================
評価で使う指標

・平均二乗誤差
元の目的変数yと、予測されたyがどれくらいずれているのか、そのずれの二乗の平均。
この数字だけでは、良いのか悪いのかわからない

・決定係数
目的変数の分布に左右されず、全てのデータに置いて、予測が当たっていたら1.0
当てはまりが悪い時は0を下回ることもある



SVRで非線形回帰=SVR(kernel='rbf',C=10) 			# 学習用オブジェクト作成
SVRで非線形回帰.fit(学習データX,学習データy)			# オブジェクト.fitで学習
学習データで予測されたy=SVRで非線形回帰.predict(学習データX) 	# オブジェクト.predictで予測
テストデータで予測されたy=SVRで非線形回帰.predict(テストデータX)	# 同上

mean_squared_error(学習データy,学習データで予測されたy)	# 学習データでの平均二乗誤差
r2_score(学習データy,学習データで予測されたy)			# 学習データでの決定係数            

⭐️平均二乗誤差は小さい方が、決定係数は大きい方が予測がうまくいっている。


過学習（オーバーフィッティング）
学習データについてはうまく予測できるが、 テストデータについてはできない
テストデータ（未知のデータ）に対する予測性能が「汎化性能」


過学習を防ぐには。。
データを増やす
特徴量（次元）を削減する（単純にする）
正則化する（モデルが複雑になりすぎないようにする）


train_test_split()
ランダムに学習データとテストデータを分割する関数

「たまたまじゃない？」→　交差検証（超定番）
ランダムに分けながら評価する、を何回か繰り返す。






























